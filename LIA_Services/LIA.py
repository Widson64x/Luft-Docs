# /routes/ia.py
import os
import re
import uuid
from flask import Blueprint, jsonify, request, session
from LIA_Services.Services import Context_Service, Feedback_Service
from Utils.auth.auth_utils import login_required
from Config import MODULES_DIR, BASE_PREFIX

# --- IMPORTA√á√ïES DOS SERVI√áOS DE IA ---
from LIA_Services import LIAResponseGenerator
from LIA_Services.Configs.LLMConfig import are_components_available
from Utils.recommendation_service import log_ai_feedback

ia_bp = Blueprint('ia_bp', __name__)


def _transform_path_to_url(file_path, token):
    """
    Recebe um caminho de arquivo (ex: data/modules/rh/doc.md) e o token,
    retornando a URL clic√°vel correta para a aplica√ß√£o.
    """
    if not file_path:
        return "#"

    # 1. Normalizar as barras para evitar problemas entre Windows (\) e Linux (/)
    clean_path = file_path.replace('\\', '/')
    
    # URL Base (ex: /luft-docs)
    base_url = BASE_PREFIX

    # --- CASO 1: √â UM M√ìDULO? ---
    # Estrutura padr√£o: data/modules/<NOME_DO_MODULO>/...
    if '/modules/' in clean_path:
        try:
            # Quebra o caminho para pegar o nome da pasta logo ap√≥s 'modules'
            parts = clean_path.split('/modules/')
            if len(parts) > 1:
                sub_parts = parts[1].split('/') # Pega o resto do caminho
                module_name = sub_parts[0]      # O primeiro item √© a pasta do m√≥dulo
                
                # Retorna link para a rota de M√≥dulo
                return f"{base_url}/modulo/?modulo={module_name}&token={token}"
        except Exception as e:
            print(f"Erro ao gerar link de m√≥dulo: {e}")

    # --- CASO 2: √â UM SUBM√ìDULO OU ARQUIVO GLOBAL? ---
    # Estrutura: data/global/.../NOME_ARQUIVO.md
    # A l√≥gica aqui √© pegar o nome do arquivo (sem extens√£o) e passar como ?nome=
    if clean_path.endswith('.md'):
        try:
            filename = os.path.basename(clean_path) # Ex: TORRE_DE_CONTROLE.md
            name_no_ext = os.path.splitext(filename)[0] # Ex: TORRE_DE_CONTROLE
            
            # Retorna link para a rota de Subm√≥dulo
            return f"{base_url}/submodule/?nome={name_no_ext}&token={token}"
        except Exception as e:
            print(f"Erro ao gerar link de subm√≥dulo: {e}")

    # Fallback: Se n√£o conseguir identificar, retorna '#' ou o pr√≥prio caminho
    return "#"

# --- A L√ìGICA DE DESCOBRIR M√ìDULOS PERMANECE AQUI ---
def get_available_modules():
    """Verifica o diret√≥rio data/modules e retorna uma lista com os nomes dos m√≥dulos."""
    try:
        modules_path = str(MODULES_DIR)
        if not os.path.exists(modules_path):
            print("AVISO: Diret√≥rio 'data/modules' n√£o encontrado.")
            return []
        available = sorted([d for d in os.listdir(modules_path) if os.path.isdir(os.path.join(modules_path, d))])
        print(f"M√≥dulos descobertos automaticamente: {available}")
        return available
    except Exception as e:
        print(f"ERRO CR√çTICO ao descobrir m√≥dulos: {e}")
        return []

AVAILABLE_MODULES = get_available_modules()
# -------------------------------------------------------------

@ia_bp.route('/api/get_modules_list', methods=['GET'])
@login_required
def get_modules_list():
    """Retorna a lista de m√≥dulos dispon√≠veis para o frontend."""
    if not AVAILABLE_MODULES:
        return jsonify({"error": "Nenhum m√≥dulo dispon√≠vel."}), 404
    return jsonify({"modules": AVAILABLE_MODULES})

@ia_bp.route('/api/ask_llm', methods=['POST'])
@login_required
def ask_llm_api():
    if not are_components_available():
        return jsonify({"error": "Componentes da IA n√£o est√£o configurados."}), 500

    data = request.get_json()
    original_user_question = data.get('user_question')
    if not original_user_question:
        return jsonify({"error": "Requisi√ß√£o inv√°lida."}), 400

    selected_model = data.get('selected_model', 'groq-70b')
    user_id = session.get('username', 'anonymous')
    user_perms = session.get('permissions', {})
    response_uuid = str(uuid.uuid4())

    # **L√ìGICA CORRIGIDA**: Verifica se √© uma busca focada para pular o reranking
    is_focused_search = '@' in original_user_question

    try:
        # ETAPA 1: BUSCA INICIAL DE DOCUMENTOS CANDIDATOS
        initial_docs, initial_metas, was_blocked_by_perm = Context_Service.find_context_for_question(
            user_question=original_user_question,
            available_modules=AVAILABLE_MODULES,
            user_perms=user_perms
        )

        if was_blocked_by_perm:
            no_access_answer = "N√£o encontrei informa√ß√µes sobre este t√≥pico nos documentos aos quais voc√™ tem acesso. Tente perguntar de outra forma ou sobre outro assunto."
            return jsonify({
                "answer": no_access_answer, "context_files": [], "response_id": response_uuid,
                "user_id": user_id, "original_user_question": original_user_question,
                "model_used": selected_model, "context_sources_list": []
            })
        
        if not initial_docs:
            no_context_answer = "Opa! N√£o encontrei nada sobre isso nos documentos. Pode tentar perguntar de outra forma? üòâ"
            return jsonify({
                "answer": no_context_answer, "context_files": [], "response_id": response_uuid,
                "user_id": user_id, "original_user_question": original_user_question,
                "model_used": selected_model, "context_sources_list": []
            })

        final_context = ""
        final_sources = []

        # ETAPA 2: RE-RANKING CONDICIONAL
        if not is_focused_search:
            # Para buscas gerais, usamos o reranker para obter a melhor qualidade.
            final_context, final_sources = LIAResponseGenerator.rerank_and_filter_context(
                question=original_user_question,
                documents=initial_docs,
                metadatas=initial_metas
            )
        else:
            # Para buscas com '@', pulamos o reranker e usamos os resultados diretos.
            print("Busca focada com '@' detectada. Pulando a etapa de re-ranking para maior velocidade.")
            # Apenas pegamos os 4 melhores resultados da busca vetorial inicial.
            top_k = 4
            final_context = "\n---\n".join(initial_docs[:top_k])
            final_sources = sorted(list(set(meta['source'] for meta in initial_metas[:top_k])))

        if not final_context.strip():
            no_context_answer = "Encontrei alguns documentos, mas nenhum parecia responder diretamente √† sua pergunta. Poderia tentar ser mais espec√≠fico? ü§î"
            return jsonify({
                "answer": no_context_answer, "context_files": [], "response_id": response_uuid,
                "user_id": user_id, "original_user_question": original_user_question,
                "model_used": selected_model, "context_sources_list": []
            })

        # ETAPA 3: GERA√á√ÉO DA RESPOSTA FINAL
        final_answer = LIAResponseGenerator.generate_llm_answer(
            model_name=selected_model,
            context=final_context,
            question=original_user_question
        )

        # --- NOVA L√ìGICA DE LINKS ---
        # Pega o token atual da sess√£o (ou do request se voc√™ estiver passando via header)
        # Como o usu√°rio j√° est√° logado para chamar essa rota, pegamos o token que veio no request (query param) ou geramos um novo se necess√°rio.
        # Mas para facilitar, vamos pegar o que o frontend mandou ou da sess√£o.
        
        # Tenta pegar token do parametro, header ou sess√£o
        current_token = request.args.get('token') 
        if not current_token:
             # Se n√£o veio na query, tentamos pegar da sess√£o se voc√™ salvou l√°, 
             # ou assumimos que o frontend vai ter que lidar com isso. 
             # No seu caso, o frontend JS passa o token na URL ao carregar, mas aqui √© um POST.
             # Vamos tentar reconstruir ou usar um placeholder se n√£o tiver.
             current_token = session.get('token', '')

        # Processa as fontes para criar objetos com Link
        structured_sources = []
        for source in final_sources:
            link = _transform_path_to_url(source, current_token)
            structured_sources.append({
                "name": source,  # O caminho original (para exibir texto)
                "url": link      # O link clic√°vel
            })

        return jsonify({
            "answer": final_answer,
            "context_files": final_sources, # Mant√©m compatibilidade legada se precisar
            "response_id": response_uuid,
            "user_id": user_id,
            "original_user_question": original_user_question,
            "model_used": selected_model,
            "context_sources_objects": structured_sources # <--- CAMPO NOVO COM LINKS
        })

    except Exception as e:
        print(f"ERRO CR√çTICO na API ask_llm: {e}")
        return jsonify({"error": f"Ocorreu um erro inesperado: {str(e)}"}), 500
    
@ia_bp.route('/api/submit_feedback', methods=['POST'])
@login_required
def submit_feedback_api():
    data = request.get_json()
    response_id = data.get('response_id')
    user_id = session.get('username', 'anonymous')
    rating = data.get('rating')
    comment = data.get('comment')
    # NOVOS: Recebe os campos adicionais do frontend
    user_question = data.get('user_question')
    model_used = data.get('model_used')
    context_sources = data.get('context_sources') # Ser√° uma lista do frontend

    if not all([response_id, user_id, rating is not None]):
        return jsonify({"error": "Dados de feedback inv√°lidos."}), 400

    try:
        # Passa os novos campos para log_ai_feedback
        log_ai_feedback(
            response_id=response_id,
            user_id=user_id,
            rating=rating,
            comment=comment,
            user_question=user_question,
            model_used=model_used,
            context_sources=context_sources
        )
        return jsonify({"message": "Feedback registrado com sucesso!"}), 200
    except Exception as e:
        print(f"Erro ao registrar feedback: {e}")
        return jsonify({"error": "Erro interno ao registrar feedback."}), 500